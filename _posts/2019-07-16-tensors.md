---
layout: post



category:  [math]
categories:  [math, physics]
tags:  [math, tensors, physics, differential]
title: Tensors
author: Aaron Kirtland
published: false
---



# Tensors and Maxwell's Equations

## Introduction

Here I'll be building up to interpreting Maxwell's equations with tensors.
I'm using the following references:


- <https://www.ese.wustl.edu/~nehorai/Porat_A_Gentle_Introduction_to_Tensors_2014.pdf>
- Wikipedia


At times, I may include information not directly pertinent to the goal, but just because it may be helpful to compare definitions to other previously-studied topics.

## Tensor

<div class="definition" text="tensor">
A $(p,q)$ tensor $T‚àà \underbrace{V‚äó ‚Ä¶ ‚äó V}_{p\text{copies}} ‚äó \underbrace{V^* ‚äó ‚Ä¶ ‚äó V^*}_{q \text{copies}}$
</div>

## Operations on tensors

<div class="definition" text="contraction">
Let $T$ have type $(a,b)$.
The $(i,j)$th contraction of $T$ is $T_{t_1,‚Ä¶,t_{j-1},k,t_{j+1},‚Ä¶,t_b}^{s_1,‚Ä¶,s_{i-1},k,s_{i+1},‚Ä¶,s_a}$
</div>

<div class="definition" text="raising and lowering">
</div>

<div class="definition" text="Levi-Civita symbol">
  \[Œµ_{i_1,‚Ä¶,i_n}=\begin{cases}1 & i_1,‚Ä¶,i_n \text{even} \\ -1 & \text{odd} \\ 0 & \text{not a permutation}\end{cases}\]
</div>

<div class="example">
  \[\det(A)=Œµ_{i_1,‚Ä¶,i_n}A^1_{i_1}‚ãØ A^n_{i_n}\]
</div>

## Beginning

<div class="definition" text="Gram Matrix">
Let $B$ be a bilinear form on a vector space $V$.
The Gram Matrix $G$ is defined by $G_{ij}=B(v_i,v_j)$.
</div>

One property of the gram matrix is that $\{v_i\}$ are linearly independent iff $\det(G)‚â†0$.
I remember learning about this matrix once in machine learning class as well in the context of kernel functions.

## Equivalence relations on matrices

<div class="definition">
Two $n√ón$ matrices $A$ and $B$ are similar if there exists a $P$ such that $B=P^{-1}AP$, ie if $A$ and $B$ are in the same conjugacy class of $GL(n,ùîΩ)$. 
</div>

Similar matrices are the same matrix with respect to a different basis, and this similar matrices share all non-basis-dependent properties.

<div class="definition" text="Matrix congruence">
Let $A$ and $B$ be $n√ón$ matrices over $ùîΩ$.
$A$ and $B$ are congruent if there exists an invertible $P$ such that $B=P^{T}AP$.
</div>

Matrix equivalence is defined, in general, on rectangular matrices, and is more restrictive than similarity.

## Back to the program

<div class="theorem" text="Sylvestor">
Every real symmetric matrix Gram matrix $G$ is congruent to a diagonal matrix $Œõ$ with entries $0,¬±1$ that is unique up to congruence.
</div>
<div class="proof">
  
</div>

<div class="definition">
An $n√ón$ symmetric real matrix $M$ is positive semidefinite if for all $x‚àà ‚Ñù ^n$, $x^{T}Mx‚â•0$.
If $x^{T}Mx=0‚áí x=0$, then $M$ is positive definite.
Negative semidefinite and negative definite matrices are defined similarly.
</div>

Equivalently, a positive definite matrix has all positive eigenvalues, a positive semidefinite matrix has all nonnegative eigenvalues, and so on.

TODO proof

<div class="definition" text="signature">
Let $n^+,n^-,n^0$ be the number of $+1,-2,0$, respectively, in $Œõ$.
$(n^+,n^-,n^0)$ is called the signature of $G$.
</div>

When $\{V\}$ are linearly independent, then $G$ is positive-definite, so because it is symmetric, 

<div class="theorem">
If $G$ is positive, then it is positive definite.
</div>
<div class="proof">
\begin{equation*}
\begin{split}
  x^{T}Gx
&=‚àë_{i,j}x_i G_{ij} x_j \\
&=<‚àë_i x_i v_i,‚àë_j x_j v_j> \\
&=\Vert ‚àë_i v_i x_i \Vert^2 \\
&‚â•0
\end{split}
\end{equation*}
</div>

Note that $B$ is a bilinear form, not a Hermitian inner product.
It turns out that if $G$ is positive, then the space is Euclidean.

TODO elaborate

## The metric tensor

<div class="definition" text="metric tensor">
The metric tensor $g_{ij}$ of an inner product space is a $(0,2)$ tensor with coordinates under $\{v\}$ given by the Gram matrix.
</div>

Because $G$ is nonsingular, there is a dual metric tensor $g^{ij}$ that satisfies $g_{ij}g^{jk}=Œ¥_i^k$

Why are tensors multiplies like matrices? TODO


## types of potentials

<div class="definition" text="scalar potential">
A scalar potential is a vector field whose gradient $v=-‚àá Œ¶$ is a vector field. 
Then for $Œ¶$ $C^1$ on $U$, $v:U‚Üí ‚Ñù ^n$, where $U‚äÇ ‚Ñù ^n$ is open, is said to be conservative and curl-free as the curl vanishes everywhere.
</div>

<div class="definition" text="Vector potential">
A vector potential is a vector field $A$ whose curl $‚àá √óA$ is a vecctor field.
</div>

<div class="theorem">
Let $v:‚Ñù ^3‚Üí ‚Ñù ^3$ be a twice continuously differentiable solenoidal vector field, and that $v(x)$ decreases sufficiently fast as $||x||‚Üí ‚àû$.
Then $A(x)=\frac{1}{4œÄ}‚à´_{‚Ñù ^3} \frac{‚àá _y√óv(y)}{\Vert x-y\Vert}d^3y$
is a vector potential for $v$.
</div>

This contrustuction can be generalized for an arbitrary Helmholtz decomposition.
This is not unique, as for any scalar function $m‚àà C^1$, $v=A+‚àá m$.

<div class="question">
Do there exist scalar potentials that are not of the above form, $A+‚àá m$?
</div>

This also relates to "gauge fixing".

<div class="theorem" text="Helmholtz decomposition">
Let $F$ be a vector field on a bounded $V‚äÜ ‚Ñù ^3$ that is twice continuosly differentiable.
Then there exists a scalar potential $Œ¶$ and vector potential $A$ such that $F=-‚àá Œ¶+‚àá √ó A$.
</div>
<div class="proof">
TODO

- what is differentiability over a vector field
- <https://en.wikipedia.org/wiki/Helmholtz_decomposition>

</div>

$-‚àá Œ¶$ is also called the longitudinal partof $F$, and $‚àá √ó A$ is also called the transverge part of $F$.

## electromagnetic potentials

<div class="definition">
The magnetic vector potential $A$ is a vector potential of the magnetic field $B$
</div>

<div class="definition" text="electric potential">
Let $F=E+\frac{‚àÇA}{‚àÇt}$.
By Faraday's law, $F$ is conservative.
TODO why is this? <https://en.wikipedia.org/wiki/Electric_potential>
Therefore, $E=-‚àá V-\frac{‚àÇA}{‚àÇt}$, where $V$ is the scalar potential defined by $F$.
</div>

Note that in the electrostatic case, we have that $V$ is a scalar potential of $E$.
Also, we will be using both $V$ and $œÜ$ to refer to the electric potential unless these symbols are otherwise defined.

<div class="definition" text="electromagnetic four-potential">
$A^Œ±=(œÜ/c,A)$.
</div>

<div class="definition" text="four-gradient">
$‚àÇ_Œº=(\frac{1}{c}\frac{‚àÇ}{‚àÇt},‚àá )=(\frac{‚àÇ_t}{c},‚àá )$
</div>

<div class="definition" text="category of manifolds">
$\Man^p$ is the category whose objects are manifolds of smoothness class $C^p$ and whose morphisms are $p$-times differentiable maps.
Similarly, the category of smooth manifolds is $\Man^‚àû$ and the category of analytic manifolds is $\Man^œâ$.
</div>

TODO what does it mean looking at manifolds modeled on a fixed caegory $A$?

## category theory

Here I'll try to build up to categorically describing a differential form.

<https://ncatlab.org/nlab/show/differentiable+manifold>
<https://ncatlab.org/nlab/show/tangent+bundle>

<div class="definition" text="bundle">
A bundle over an object $B$ in a category $C$ is an object $E$ of $C$ together with a morphism $p:E‚Üí B$.
</div>

<div class="definition" text="section">
  <https://ncatlab.org/nlab/show/section>
</div>

<div class="definition" text="tangency relation">
</div>

<div class="definition" text="tangent vector">
A tangent vector on $X$ at $x$ is an equivalence class of the tangency equivalence relation, and the set of all tangent vectors at $x‚àà X$ is denoted $T_x X$.
</div>

<div class="definition">
A coordinate chart is a map $œÜ:‚Ñù ^n\xrightarrow[‚âÖ ] X|_{\im œÜ}‚Ü™ X$
</div>

<div class="theorem">
$T_x X$ is a real vector space.
</div>
<div class="proof">
</div>

<div class="definition" text="exterior algebra">
  <https://ncatlab.org/nlab/show/exterior+algebra>
</div>

<div class="definition" text="differential form">
  <https://ncatlab.org/nlab/show/differential+form>
</div>

This content is necessary for seeing pullbacks generally, but might not be immediately necessary for our goal.

<div class="definition" text="fiber">
The fiber of a morphism of bundle $f:E‚Üí B$ over a point $x$ of $B$ is the collection of generalized elements of $E$ that are mapped by $f$ to $x$.
</div>

<div class="definition" text="pullback">
  
</div>

TODO

- <https://ncatlab.org/nlab/show/pullback>
- <https://ncatlab.org/nlab/show/fiber>
- <https://ncatlab.org/nlab/show/bundle>
- <https://ncatlab.org/nlab/show/differential+form>


## TODO


- <https://en.wikipedia.org/wiki/Electromagnetic_tensor>
- <https://en.wikipedia.org/wiki/Electromagnetic_four-potential>
- <https://en.wikipedia.org/wiki/Exterior_derivative#Exterior_derivative_of_a_k-form>



